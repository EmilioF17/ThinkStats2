{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16ee9ab3-4e7c-4415-8a27-963606393466",
   "metadata": {},
   "source": [
    "# Week 7 - DSC 530 - Emilio Flores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e75fa3-9685-497d-83cb-d2dfd25fd484",
   "metadata": {},
   "source": [
    "## Chapter 9 - Exercise 9.1\n",
    "As sample size increases, the power of a hypothesis test increases, which means it is more likely to be positive if the effect is real. Conversely, as sample size decreases, the test is less likely to be positive even if the effect is real.\n",
    "\n",
    "To investigate this behavior, run the tests in this chapter with different subsets of the NSFG data. You can use thinkstats2.SampleRows to select a random subset of the rows in a DataFrame.\n",
    "\n",
    "What happens to the p-values of these tests as sample size decreases? What is the smallest sample size that yields a positive test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65b83ac3-b8f8-47aa-82c7-6fbbefec5aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import thinkstats2\n",
    "import random\n",
    "import first\n",
    "import numpy as np\n",
    "live, firsts, others = first.MakeFrames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "55f06bb7-6019-44a5-b39c-5ab7c4bb682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PregLengthTest(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def MakeModel(self):\n",
    "        firsts, others = self.data\n",
    "        self.n = len(firsts)\n",
    "        self.pool = np.hstack((firsts, others))\n",
    "\n",
    "        pmf = thinkstats2.Pmf(self.pool)\n",
    "        self.values = range(35, 44)\n",
    "        self.expected_probs = np.array(pmf.Probs(self.values))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data\n",
    "    \n",
    "    def TestStatistic(self, data):\n",
    "        firsts, others = data\n",
    "        stat = self.ChiSquared(firsts) + self.ChiSquared(others)\n",
    "        return stat\n",
    "\n",
    "    def ChiSquared(self, lengths):\n",
    "        hist = thinkstats2.Hist(lengths)\n",
    "        observed = np.array(hist.Freqs(self.values))\n",
    "        expected = self.expected_probs * len(lengths)\n",
    "        stat = sum((observed - expected)**2 / expected)\n",
    "        return stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e386535-bcff-4c52-964a-f297a45e8435",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CorrelationPermute(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        xs, ys = data\n",
    "        test_stat = abs(thinkstats2.Corr(xs, ys))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        xs, ys = self.data\n",
    "        xs = np.random.permutation(xs)\n",
    "        return xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d90c4ae7-26c9-48c1-9bf3-6c4d6502c4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffMeansPermute(thinkstats2.HypothesisTest):\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        group1, group2 = data\n",
    "        test_stat = abs(group1.mean() - group2.mean())\n",
    "        return test_stat\n",
    "\n",
    "    def MakeModel(self):\n",
    "        group1, group2 = self.data\n",
    "        self.n, self.m = len(group1), len(group2)\n",
    "        self.pool = np.hstack((group1, group2))\n",
    "\n",
    "    def RunModel(self):\n",
    "        np.random.shuffle(self.pool)\n",
    "        data = self.pool[:self.n], self.pool[self.n:]\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6418609e-a26c-421d-b3cf-e9293d54562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunTests(live, iters=1000):\n",
    "    \"\"\"Runs the tests from Chapter 9 with a subset of the data.\n",
    "\n",
    "    live: DataFrame\n",
    "    iters: how many iterations to run\n",
    "    \"\"\"\n",
    "    n = len(live)\n",
    "    firsts = live[live.birthord == 1]\n",
    "    others = live[live.birthord != 1]\n",
    "\n",
    "    # compare pregnancy lengths\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p1 = ht.PValue(iters=iters)\n",
    "\n",
    "    data = (firsts.totalwgt_lb.dropna().values,\n",
    "            others.totalwgt_lb.dropna().values)\n",
    "    ht = DiffMeansPermute(data)\n",
    "    p2 = ht.PValue(iters=iters)\n",
    "\n",
    "    # test correlation\n",
    "    live2 = live.dropna(subset=['agepreg', 'totalwgt_lb'])\n",
    "    data = live2.agepreg.values, live2.totalwgt_lb.values\n",
    "    ht = CorrelationPermute(data)\n",
    "    p3 = ht.PValue(iters=iters)\n",
    "\n",
    "    # compare pregnancy lengths (chi-squared)\n",
    "    data = firsts.prglngth.values, others.prglngth.values\n",
    "    ht = PregLengthTest(data)\n",
    "    p4 = ht.PValue(iters=iters)\n",
    "\n",
    "    print('%d\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f' % (n, p1, p2, p3, p4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2b8cbebc-e539-4577-bf16-f197c158a139",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9148\t0.16\t0.00\t0.00\t0.00\n",
      "4574\t0.43\t0.01\t0.00\t0.00\n",
      "2287\t0.35\t0.01\t0.00\t0.00\n",
      "1143\t0.07\t0.13\t0.09\t0.01\n",
      "571\t0.33\t0.58\t0.06\t0.15\n",
      "285\t0.77\t0.70\t0.01\t0.04\n",
      "142\t0.09\t0.76\t0.06\t0.00\n"
     ]
    }
   ],
   "source": [
    "n = len(live)\n",
    "for _ in range(7):\n",
    "    sample = thinkstats2.SampleRows(live, n)\n",
    "    RunTests(sample)\n",
    "    n //= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40b125-17be-4401-b7ea-c713950d0166",
   "metadata": {},
   "source": [
    "Results tend to be positive the larger the sample is, nevertheless, there are stil some positive results in smaller\n",
    "samples. For example, a sample of 142 units yielded a positive result. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0d205c-e833-4397-8392-76afff0d1b10",
   "metadata": {},
   "source": [
    "## Chapter 10 - Exercise 10.1s?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46b0ebe-9104-4620-9336-99d09c9aa3c0",
   "metadata": {},
   "source": [
    "### Linear least squares fit for log(weight) vs. height\n",
    "Using the data from the BRFSS, compute the linear least squares fit for log(weight) versus height. How would you best present the estimated parameters for a model like this where one of the variables is log-transformed? If you were trying to guess someoneâ€™s weight, how much would it help to know their height?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4dbb3413-dd37-48e3-9a5b-a86b6a851fc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9930804163932863, 0.005281454169417785)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import brfss\n",
    "\n",
    "df = brfss.ReadBrfss(nrows=None)\n",
    "df = df.dropna(subset=['htm3', 'wtkg2'])\n",
    "heights, weights = df.htm3, df.wtkg2\n",
    "log_weights = np.log10(weights)\n",
    "\n",
    "inter, slope = thinkstats2.LeastSquares(heights, log_weights)\n",
    "inter, slope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f1a277-c420-46ea-91a5-6695be5ec9bf",
   "metadata": {},
   "source": [
    "```\n",
    "The estimated parameters could be represented like this:\n",
    "Log10(weight) = 0.9931 + (0.005 * height)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1883e73-e356-416c-8f54-a19b66790207",
   "metadata": {},
   "source": [
    "```\n",
    "Height would be very helpful to guess someone's weight as there is a positive relationship between both.\n",
    "What would be the weight for someone that is 170cm tall?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "38fe3bbe-aeff-446c-a06f-26b815ac6a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weight of someone that is 170 cm tall is 77.79 kg according to this model\n"
     ]
    }
   ],
   "source": [
    "height = 170\n",
    "weight = 10 ** (inter + (slope * height))\n",
    "print(f\"The weight of someone that is {height} cm tall is {round(weight, 2)} kg according to this model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce075cc5-3675-44b9-9ece-0218ecc95554",
   "metadata": {},
   "source": [
    "### Resampling\n",
    "Like the NSFG, the BRFSS oversamples some groups and provides a sampling weight for each respondent. In the BRFSS data, the variable name for these weights is totalwt. Use resampling, with and without weights, to estimate the mean height of respondents in the BRFSS, the standard error of the mean, and a 90% confidence interval. How much does correct weighting affect the estimates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c9b6e91-5a40-4679-b51c-fddec20b65d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted:\n",
      "Mean Height: 168.95\n",
      "Standard Error: 0.02\n",
      "90% Confidence Interval: 168.92 - 168.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function that calculates mean height, standard error of the mean, and 90% confidence interval\n",
    "\n",
    "def Summarize(estimates):\n",
    "    mean = np.mean(estimates)\n",
    "    stderr = np.std(estimates)\n",
    "    ci = np.percentile(estimates, [5, 95])  # 90% confidence interval\n",
    "    return mean, stderr, ci\n",
    "\n",
    "\n",
    "# Resampling without weight\n",
    "estimates_unweighted = [thinkstats2.ResampleRows(df).htm3.mean() for _ in range(100)]\n",
    "\n",
    "mean_unweighted, stderr_unweighted, ci_unweighted = Summarize(estimates_unweighted)\n",
    "\n",
    "print(\"Unweighted:\")\n",
    "print(\"Mean Height:\", round(mean_unweighted, 2))\n",
    "print(\"Standard Error:\", round(stderr_unweighted, 2))\n",
    "print(\"90% Confidence Interval:\", round(ci_unweighted[0], 2), \"-\", round(ci_unweighted[1], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2fc0d9ae-a3ce-49f3-89bb-1c07d89906c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Weighted:\n",
      "Mean Height: 170.5\n",
      "Standard Error: 0.02\n",
      "90% Confidence Interval: 170.47 - 170.52\n"
     ]
    }
   ],
   "source": [
    "def ResampleRowsWeighted(df, weight_col):\n",
    "    weights = df[weight_col] / df[weight_col].sum()\n",
    "    return df.sample(n=len(df), replace=True, weights=weights)\n",
    "\n",
    "estimates_weighted = [ResampleRowsWeighted(df, 'finalwt').htm3.mean() for _ in range(100)]\n",
    "mean_weighted, stderr_weighted, ci_weighted = Summarize(estimates_weighted)\n",
    "print(\"\\nWeighted:\")\n",
    "print(\"Mean Height:\", round(mean_weighted, 2))\n",
    "print(\"Standard Error:\", round(stderr_weighted, 2))\n",
    "print(\"90% Confidence Interval:\", round(ci_weighted[0], 2), \"-\", round(ci_weighted[1], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b75ebca3-ba5c-424d-a9e5-fe50daa20f56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Effect of Weighting:\n",
      "Difference in Mean Height: 1.54\n",
      "Difference in Standard Error: -0.0\n"
     ]
    }
   ],
   "source": [
    "# Compare the effect of weighting\n",
    "effect_on_mean = mean_weighted - mean_unweighted\n",
    "effect_on_stderr = stderr_weighted - stderr_unweighted\n",
    "\n",
    "print(\"\\nEffect of Weighting:\")\n",
    "print(\"Difference in Mean Height:\", round(effect_on_mean, 2))\n",
    "print(\"Difference in Standard Error:\", round(effect_on_stderr, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d55dc-77b1-425a-b9fb-a90e9a772e4e",
   "metadata": {},
   "source": [
    "```\n",
    "The correct weighting affects estimates by almost 2 cm\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
