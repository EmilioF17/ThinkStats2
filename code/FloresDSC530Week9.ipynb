{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4c0aef5-5e92-4348-a094-b43192b50a6f",
   "metadata": {},
   "source": [
    "# Emilio Flores - DSC 510 Exercise - Week 9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90327ea-68b0-485b-9463-81c6aa2feda9",
   "metadata": {},
   "source": [
    "## Exercise 12.1\n",
    "The linear model I used in this chapter has the obvious drawback that it is linear, and there is no reason to expect prices to change linearly over time. We can add flexibility to the model by adding a quadratic term, as we did in \"Nonlinear Relationships\" on page 133.\n",
    "\n",
    "Use a quadratic model to fit the time series of daily prices, and use the model to generate predictions. You will have to write a version of RunLinearModel that runs that quadratic model, but after that you should be able to reuse code in timeseries.py to generate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "06a7e446-dc8f-4092-844e-b15baca07856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import thinkstats2\n",
    "import thinkplot\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7fe8cbab-59a2-4588-bff1-aed5fb4c93b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(\"mj-clean.csv\", parse_dates=[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "10011f0e-712d-4d3f-b48c-81b33173cad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GroupByDay(transactions, func=np.mean):\n",
    "    \"\"\"Groups transactions by day and compute the daily mean ppg.\n",
    "\n",
    "    transactions: DataFrame of transactions\n",
    "\n",
    "    returns: DataFrame of daily prices\n",
    "    \"\"\"\n",
    "    grouped = transactions[[\"date\", \"ppg\"]].groupby(\"date\")\n",
    "    daily = grouped.aggregate(func)\n",
    "\n",
    "    daily[\"date\"] = daily.index\n",
    "    start = daily.date[0]\n",
    "    one_day = np.timedelta64(1, \"D\")\n",
    "    daily[\"years\"] = (daily.date - start) / (one_day * 365.25)  # Convert days to years\n",
    "\n",
    "    # print(\"Daily DataFrame after adding 'years':\")\n",
    "    # print(daily.head())\n",
    "\n",
    "    return daily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "66177b96-d519-4404-8062-313f43ffef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GroupByQualityAndDay(transactions):\n",
    "    \"\"\"Divides transactions by quality and computes mean daily price.\n",
    "\n",
    "    transaction: DataFrame of transactions\n",
    "\n",
    "    returns: map from quality to time series of ppg\n",
    "    \"\"\"\n",
    "    groups = transactions.groupby(\"quality\")\n",
    "    dailies = {}\n",
    "    for name, group in groups:\n",
    "        dailies[name] = GroupByDay(group)\n",
    "        # print(f\"Processed quality group: {name}\")\n",
    "\n",
    "    return dailies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "b3198c83-9e50-4de1-8912-46c6b80a6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunQuadraticModel(daily):\n",
    "    \"\"\"Runs a linear model of prices versus years.\n",
    "\n",
    "    daily: DataFrame of daily prices\n",
    "\n",
    "    returns: model, results\n",
    "    \"\"\"\n",
    "    # print(\"Daily DataFrame before adding 'years2':\")\n",
    "    # print(daily.head())\n",
    "\n",
    "    daily[\"years2\"] = daily.years**2\n",
    "    model = smf.ols(\"ppg ~ years + years2\", data=daily)\n",
    "    results = model.fit()\n",
    "    \n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efe4fd2-fc01-4a23-b5f5-d0cd2ba6afa4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dailies = GroupByQualityAndDay(transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "7a5b48bd-55e5-4f22-8758-5d14f199d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                    ppg   R-squared:                       0.455\n",
      "Model:                            OLS   Adj. R-squared:                  0.454\n",
      "Method:                 Least Squares   F-statistic:                     517.5\n",
      "Date:                Thu, 01 Aug 2024   Prob (F-statistic):          4.57e-164\n",
      "Time:                        19:15:59   Log-Likelihood:                -1497.4\n",
      "No. Observations:                1241   AIC:                             3001.\n",
      "Df Residuals:                    1238   BIC:                             3016.\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     13.6980      0.067    205.757      0.000      13.567      13.829\n",
      "years         -1.1164      0.084    -13.326      0.000      -1.281      -0.952\n",
      "years2         0.1131      0.022      5.060      0.000       0.069       0.157\n",
      "==============================================================================\n",
      "Omnibus:                       49.112   Durbin-Watson:                   1.885\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              113.885\n",
      "Skew:                           0.199   Prob(JB):                     1.86e-25\n",
      "Kurtosis:                       4.430   Cond. No.                         27.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "name = \"high\"\n",
    "daily = dailies[name]\n",
    "\n",
    "# Run the quadratic model and print the summary\n",
    "model, results = RunQuadraticModel(daily)\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbd5b03-751d-418b-b64d-1d5f0d7b3051",
   "metadata": {},
   "source": [
    "## Exercise 12.2\n",
    "Write a definition for a class named SerialCorrelationTest that extends HypothesisTest from \"HypothesisTest\" on page 102. It should take a series and a lag as data, compute the serial correlation of the series with the given lag, and then compute the p-value of the observed correlation.\n",
    "\n",
    "Use this class to test whether the serial correlation in raw price data is statistically significant. Also test the residuals of the linear model and (if you did the previous exercise), the quadratic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "1a635af8-74d3-4564-9c8d-9fe7f5328aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SerialCorrelationTest(thinkstats2.HypothesisTest):\n",
    "    \"\"\"Tests serial correlations by permutation.\"\"\"\n",
    "\n",
    "    def TestStatistic(self, data):\n",
    "        \"\"\"Computes the test statistic.\n",
    "\n",
    "        data: tuple of xs and ys\n",
    "        \"\"\"\n",
    "        series, lag = data\n",
    "        test_stat = abs(SerialCorr(series, lag))\n",
    "        return test_stat\n",
    "\n",
    "    def RunModel(self):\n",
    "        \"\"\"Run the model of the null hypothesis.\n",
    "\n",
    "        returns: simulated data\n",
    "        \"\"\"\n",
    "        series, lag = self.data\n",
    "        permutation = series.reindex(np.random.permutation(series.index))\n",
    "        return permutation, lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "54b8ea6f-4640-4e15-895f-4f7932128c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SerialCorr(series, lag=1):\n",
    "    xs = series[lag:]\n",
    "    ys = series.shift(lag)[lag:]\n",
    "    corr = thinkstats2.Corr(xs, ys)\n",
    "    return corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "0a8239a6-0406-4df9-a9e8-31b115909838",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RunLinearModel(daily):\n",
    "    model = smf.ols(\"ppg ~ years\", data=daily)\n",
    "    results = model.fit()\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "1bf08867-4255-4967-abb6-3b7ca17e9502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4852293761947381 0.0\n"
     ]
    }
   ],
   "source": [
    "# test the correlation between consecutive prices\n",
    "\n",
    "name = \"high\"\n",
    "daily = dailies[name]\n",
    "\n",
    "series = daily.ppg\n",
    "test = SerialCorrelationTest((series, 1))\n",
    "pvalue = test.PValue()\n",
    "print(test.actual, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "c3057a03-b700-4384-8c49-df20b7d0f682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07570473767506262 0.01\n"
     ]
    }
   ],
   "source": [
    "# test for serial correlation in residuals of the linear model\n",
    "\n",
    "_, results = RunLinearModel(daily)\n",
    "series = results.resid\n",
    "test = SerialCorrelationTest((series, 1))\n",
    "pvalue = test.PValue()\n",
    "print(test.actual, pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "af262084-ac2d-4feb-9276-b695329f4e4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily DataFrame before adding 'years2':\n",
      "                  ppg       date     years    years2\n",
      "date                                                \n",
      "2010-09-02  13.384186 2010-09-02  0.000000  0.000000\n",
      "2010-09-03  14.459588 2010-09-03  0.002740  0.000008\n",
      "2010-09-04  14.923333 2010-09-04  0.005479  0.000030\n",
      "2010-09-05  16.667500 2010-09-05  0.008219  0.000068\n",
      "2010-09-06  15.537500 2010-09-06  0.010959  0.000120\n",
      "0.05607308161289919 0.045\n"
     ]
    }
   ],
   "source": [
    "# test for serial correlation in residuals of the quadratic model\n",
    "\n",
    "_, results = RunQuadraticModel(daily)\n",
    "series = results.resid\n",
    "test = SerialCorrelationTest((series, 1))\n",
    "pvalue = test.PValue()\n",
    "print(test.actual, pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
